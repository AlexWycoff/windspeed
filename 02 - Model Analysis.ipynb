{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b73532717ceab7c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89411512a29a662",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this notebook, we train, test, and evaluate the performance of an LSTM model in wind speed prediction and compare results to the persistence method, which is a common benchmark for wind speed prediction algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b2cba580d03b1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define how many time steps will be used in observation and prediction\n",
    "n_past = 7 # The last seven days of data\n",
    "n_future = 24 # The next day of data\n",
    "n_features = 6\n",
    "\n",
    "# Set the universal font size for matplotlib\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83f8ff572993e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split the series using a sliding window\n",
    "def split_series(series, n_past=n_past, n_future=n_future, offset=0):\n",
    "    X, y = list(), list()\n",
    "    for i in range(int(len(series)/(n_past))-1):\n",
    "        X.append(series[i*n_past : i*n_past + n_past, :])\n",
    "        y.append(float(series[offset + i*n_past + n_past : offset + i*n_past + n_past + n_future, 2]))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda487b9b141fb5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process and split the data for a site given its filename\n",
    "def prep_data(filename, cy=2018):\n",
    "    # Import the data for a single point\n",
    "    data = pd.read_csv(\"Data\\WTK_LED CONUS [2018-2020] 60min/\" + filename, index_col=0)\n",
    "    startyear = 2018\n",
    "\n",
    "    # Restrict the data to the last 5 years, giving us 4 years of training and 1 year of testing data\n",
    "    data = data.iloc[int(len(data)*(cy-startyear)/20):]\n",
    "\n",
    "    # Split the data into training and testing samples\n",
    "    cutoff = int(len(data)*0.8)\n",
    "    test_data = data.iloc[cutoff:]\n",
    "    data = data.iloc[:cutoff]\n",
    "    \n",
    "    # Designate which columns are used for training\n",
    "    columns = [5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    # Normalize the testing and training data\n",
    "    test_data.iloc[:, columns], test_norms = normalize(test_data.iloc[:, columns], axis=0, norm='max', return_norm=True)\n",
    "    data.iloc[:, columns], train_norms = normalize(data.iloc[:, columns], axis=0, norm='max', return_norm=True)\n",
    "\n",
    "    # Split the data into series for training\n",
    "    X_train, y_train = split_series(np.array(data.iloc[:, columns]), n_future=1, offset=24-1)\n",
    "    X_test, y_test = split_series(np.array(test_data.iloc[:, columns]), n_future=1, offset=24-1)\n",
    "\n",
    "    # Adjust the expected output to contain only the wind speed\n",
    "    # y_train, y_test = y_train[:, :, 2], y_test[:, :, 2]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, train_norms, test_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ecadfc9437cad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "def define_model():\n",
    "    # Lighter model used for additional training\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Input(shape=(n_past, n_features)))\n",
    "    model.add(LSTM(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(Dense(1, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343d8cad2878f10",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = define_model()\n",
    "model.summary()\n",
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data('7871' + '.csv', cy=2018)\n",
    "model = define_model()\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test), batch_size=128)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(mean_absolute_error(y_test * test_norms[2], predictions * train_norms[2]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "582fd03776ec9732",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train models for every selected site\n",
    "i = 1\n",
    "df1 = pd.DataFrame()\n",
    "df1['SiteID'], df1['MAE'] = list(), list()\n",
    "\n",
    "for filename in os.listdir(\"Data/Models\"):\n",
    "    print(f\"Training on site number {i} of 100\")\n",
    "    i += 1\n",
    "\n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data(filename[:-6] + '.csv', cy=2018)\n",
    "    model = define_model()\n",
    "    model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test), batch_size=128)\n",
    "    model.save(\"Data/WTK Models/\" + filename)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    df1.loc[len(df1)] = [filename[:-6], mean_absolute_error(y_test * test_norms[2], predictions * train_norms[2])]\n",
    "    \n",
    "df1.to_csv(\"Data/Raw Experiment Data/WTK Model Performance.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "418e8571b6a50426",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd7e806169f1a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train one model with data starting at different years\n",
    "df = pd.DataFrame()\n",
    "df['Years'] = list()\n",
    "df['MAE'] = list()\n",
    "for year in range(2000, 2020):\n",
    "    print(f\"{year}\")\n",
    "\n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data('7871.csv', cy=year)\n",
    "    model = define_model()\n",
    "    model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=128)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test[:, 0] * test_norms[2], predictions * train_norms[2])\n",
    "\n",
    "    df.loc[len(df) + 1] = [int(year), mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bcd17d03a0dc5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data\\Raw Experiment Data\\starting year experiment.csv')\n",
    "df['Years'] = [2020 - x for x in df['Years']]\n",
    "# Display the data for use as a figure\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")\n",
    "plt.xlabel('Years of Data')\n",
    "plt.ylabel('Mean Absolute Error (m/s)')\n",
    "plt.xlim(-2, 22)\n",
    "plt.scatter(df['Years'], df['MAE'], color='skyblue')\n",
    "y_lim = ax.get_ylim()\n",
    "plt.grid(True, axis='y', color='grey')\n",
    "\n",
    "# Plot the polynomial line of best fit\n",
    "def plot_best_fit(x, y, deg):\n",
    "    coeffs = np.polyfit(x, y, deg)\n",
    "    \n",
    "    ylist = list()\n",
    "    for n in x:\n",
    "        yvalue = np.sum([coeffs[i]*n**(len(coeffs)-1-i) for i in range(len(coeffs))])\n",
    "        ylist.append(yvalue)\n",
    "    plt.plot(x, ylist, color='skyblue')\n",
    "\n",
    "# plot_best_fit(df['Years'], df['MAE'], 3)\n",
    "\n",
    "# Plot the logarithmic line of best fit\n",
    "def plot_log_fit(x, y, deg):\n",
    "    coeffs = np.polyfit(np.log(x), y, deg)\n",
    "\n",
    "    ylist = list()\n",
    "    for n in np.log(x):\n",
    "        yvalue = np.sum([coeffs[i]*n**(len(coeffs)-1-i) for i in range(len(coeffs))])\n",
    "        ylist.append(yvalue)\n",
    "    plt.plot(x, ylist, color='skyblue')\n",
    "\n",
    "plot_log_fit(df['Years'], df['MAE'], 3)\n",
    "\n",
    "# Remove the border from the graph\n",
    "for direction in ['top', 'right', 'bottom', 'left']:\n",
    "    ax.spines[direction].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2650c1c0f9da24",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train one model with a varying number of epochs\n",
    "df = pd.DataFrame()\n",
    "df['Epochs'] = list()\n",
    "df['MAE'] = list()\n",
    "for epoch in range(10, 160, 10):\n",
    "    print(f\"{epoch}\")\n",
    "\n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data('7871.csv')\n",
    "    model = define_model()\n",
    "    model.fit(X_train,y_train,epochs=epoch,validation_data=(X_test,y_test),batch_size=128)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test[:, 0] * test_norms[2], predictions * train_norms[2])\n",
    "        \n",
    "    df.loc[len(df)+1] = [int(epoch), mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b14b9e73fe7e0b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data\\Raw Experiment Data\\epoch experiment.csv')\n",
    "# Display the data for use as a figure\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")\n",
    "plt.xlabel('Epochs Trained')\n",
    "plt.ylabel('Mean Absolute Error (m/s)')\n",
    "plt.ylim(y_lim)\n",
    "plt.scatter(df['Epochs'], df['MAE'], color='skyblue')\n",
    "plt.grid(True, axis='y', color='grey')\n",
    "\n",
    "# Plot the line of best fit\n",
    "# plot_best_fit(df['Epochs'], df['MAE'], 3)\n",
    "plot_log_fit(df['Epochs'], df['MAE'], 1)\n",
    "\n",
    "# Remove the border from the graph\n",
    "for direction in ['top', 'right', 'bottom', 'left']:\n",
    "    ax.spines[direction].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9849809ad1fda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train models for every selected site\n",
    "i = 1\n",
    "for filename in os.listdir(\"Data/NOW-23 Great Lakes [2000-2020] 60min\"):\n",
    "    print(f\"Point number {i} of 100\")\n",
    "    i += 1\n",
    "\n",
    "    model = define_model()\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data(filename, cy=2015)\n",
    "    \n",
    "    model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),batch_size=128)\n",
    "    model.save(\"Data/Models/\" + filename[:-4] + \".keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a9d64c64daf62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test models for every selected site\n",
    "mae, sites = list(), list()\n",
    "\n",
    "for filename in os.listdir(\"Data/Models\"):\n",
    "\n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data(filename[:-6] + '.csv', cy=2015)\n",
    "    model = keras.saving.load_model(\"Data/Models/\" + filename)\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    mae.append(mean_absolute_error(y_test[:, 0] * test_norms[2], predictions * train_norms[2]))\n",
    "    sites.append(filename[:-6])\n",
    "    print(mae[-1])\n",
    "df = pd.DataFrame()\n",
    "df['MAE'] = pd.Series(mae)\n",
    "df['SiteID'] = pd.Series(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29331c2c6d132ff6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, we repeat this analysis with a persistence model that uses the wind speed from 24h before as a prediction, demonstrating the superiority of the LSTM model\n",
    "\n",
    "mae, rmse, sites = list(), list(), list()\n",
    "\n",
    "for filename in os.listdir(\"Data/Models\"):\n",
    "\n",
    "    X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data(filename[:-6] + '.csv', cy=2015)\n",
    "\n",
    "    predictions = [x[-1] for x in X_test[:, :, -1]]\n",
    "    mae.append(mean_absolute_error(y_test * test_norms[2], np.array(predictions) * test_norms[2]))\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test * test_norms[2], np.array(predictions) * test_norms[2])))\n",
    "    sites.append(filename[:-6])\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1['MAE'] = pd.Series(mae)\n",
    "df1['RMSE'] = pd.Series(rmse)\n",
    "df1['SiteID'] = pd.Series(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100b6dca60797aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We compare the persistence model on a variety of loss metrics\n",
    "print(f\"Average MAE of the persistence model: {np.average(df1['MAE'])}\")\n",
    "print(f\"Median MAE of the persistence model: {np.median(df1['MAE'])}\")\n",
    "print(f\"Std MAE of the persistence model: {np.std(df1['MAE'])}\")\n",
    "print(f\"Average RMSE of the persistence model: {np.average(df1['RMSE'])}\")\n",
    "print(f\"Median RMSE of the persistence model: {np.median(df1['RMSE'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Data\\Raw Experiment Data\\Final Model Performance.csv', index_col=0)\n",
    "df1 = pd.read_csv(r\"Data/Raw Experiment Data/WTK Model Performance.csv\", index_col=0)\n",
    "\n",
    "# Generate a box plot to describe the MAE distribution for use as a figure\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")\n",
    "fig = plt.gcf()\n",
    "frame = plt.gca()\n",
    "fig.set_size_inches(12, 6)\n",
    "frame.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-ticks')\n",
    "bplot = plt.boxplot([df['MAE'], df1['MAE']], vert=False, patch_artist=True, medianprops=dict(color='black'),\n",
    "            boxprops=dict(facecolor='white'), widths=0.25)\n",
    "\n",
    "for patch, color in zip(bplot['boxes'], ['skyblue', 'seagreen']):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.xlabel(\"Mean Absolute Error (m/s)\")\n",
    "plt.tick_params(axis='x', which='major', reset=True, direction='in', top=False)\n",
    "ax.legend([bplot['boxes'][0], bplot['boxes'][1]], ['LSTM model', 'WTK Model'], loc='upper center')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec63d005f23bdfaa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can print out some statistics of the distribution in detail\n",
    "print(f\"Mean: {np.average(df['MAE'])}\")\n",
    "print(f\"Median: {np.median(df['MAE'])}\")\n",
    "print(f\"Standard Deviation: {np.std(df['MAE'])}\")\n",
    "print(f\"n: {len(df['MAE'])}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"The persistence model has a higher MAE by {(np.average(df1['MAE'])/np.average(df['MAE']) - 1) * 100}%\")\n",
    "print(f\"Median difference: {(np.median(df1['MAE'])/np.median(df['MAE']) - 1) * 100}%\")\n",
    "# Unsurpisingly, the both the median and average MAE of the persistence model are around 25-30% higher than the average LSTM model MAE over all sites"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e479075149f92bed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parameters we need for statistical inference\n",
    "diff = pd.DataFrame()\n",
    "diff['MAE'] = df1['MAE'] - df['MAE']\n",
    "print('Difference statistics')\n",
    "print(f\"Mean: {np.average(diff['MAE'])}\")\n",
    "print(f\"Median: {np.median(diff['MAE'])}\")\n",
    "print(f\"Standard Deviation: {np.std(diff['MAE'])}\")\n",
    "print(f\"n: {len(diff['MAE'])}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89cd0e7d8d966cd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e1cc26f7ca134",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To describe the differences in train time with different model parameters, we train 3 models, each encompassing the 100 selected points in the study.\n",
    "df = pd.DataFrame()\n",
    "df['Average MAE'] = list()\n",
    "df['Median MAE'] = list()\n",
    "df['Average RMSE'] = list()\n",
    "df['Median RMSE'] = list()\n",
    "df['Train_time'] = list()\n",
    "df['Train_time std'] = list()\n",
    "\n",
    "for pair in [[100, 2000], [100, 2015], [50, 2015]]:\n",
    "    # Train models for every selected site\n",
    "\n",
    "    mae, rmse, time_elapsed = list(), list(), list()\n",
    "    i = 1\n",
    "    for filename in os.listdir(\"Data/NOW-23 Great Lakes [2000-2020] 60min\"):\n",
    "        print(f\"Point number {i} of 100\")\n",
    "        i += 1\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        model = define_model()\n",
    "        X_train, y_train, X_test, y_test, train_norms, test_norms = prep_data(filename, cy=pair[1])\n",
    "        model.fit(X_train,y_train,epochs=pair[0],validation_data=(X_test,y_test),batch_size=128)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        mae.append(mean_absolute_error(y_test[:, 0] * test_norms[2], np.array(predictions) * train_norms[2]))\n",
    "        rmse.append(np.sqrt(mean_squared_error(y_test[:, 0] * test_norms[2], np.array(predictions) * train_norms[2])))\n",
    "    \n",
    "        time_elapsed.append((datetime.now() - start_time).total_seconds())\n",
    "    df.loc[len(df)+1] = [np.average(mae), np.median(mae), np.average(rmse), np.median(rmse), np.average(time_elapsed), np.std(time_elapsed)]\n",
    "df['Model'] = ['100 epochs, 20 years', '100 epochs, 5 years', '50 epochs, 5 years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34e8b15485d8ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/Raw Experiment Data/Train Time Experiment.csv\")\n",
    "\n",
    "# Now we can generate a figure to demonstrate the significant change in train time between the models\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.set_yticks(range(5, 40, 5))\n",
    "plt.grid(True, axis='y', color='grey')\n",
    "plt.bar(df['Model'], df['Train_time'], width=0.4, color=\"skyblue\")\n",
    "plt.errorbar(df['Model'], df['Train_time'], yerr=df['Train_time std'], capsize=3, linestyle=\"\", color='deepskyblue')\n",
    "plt.ylabel(\"Average train time (seconds)\")\n",
    "plt.xlabel(\"Network parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175c7c6f159a3c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We also compare the models to persistence, finding no major differences between the models in performance but significant improvements over persistence\n",
    "df.loc[len(df)+1] = [np.average(df1['MAE']), np.median(df1['MAE']), np.average(df1['RMSE']), np.median(df1['RMSE']), 0, \"Persistence\"]\n",
    "df.drop('Train_time', inplace=True, axis=1)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
